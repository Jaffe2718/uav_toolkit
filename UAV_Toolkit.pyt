# -*- coding: utf-8 -*-import os.pathimport arcpyimport torchimport mathimport numpy as npimport osfrom typing import *GPU_AVAILABLE = torch.cuda.is_available()GPU_MEMORY = torch.cuda.get_device_properties(0).total_memory / 1024 ** 3 if GPU_AVAILABLE else 0OPENCV_AVAILABLE = Falsetry:    from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor    from segment_anything.modeling.sam import Sam    from segment_anything.utils import amgexcept ImportError as ie:    arcpy.AddWarning("Warning: Dependency import error: \n{}".format(ie))try:    import cv2    OPENCV_AVAILABLE = Trueexcept ModuleNotFoundError:    arcpy.AddWarning("Warning: OpenCV is not available.")class Toolbox(object):    def __init__(self):        """Define the toolbox (the name of the toolbox is the name of the        .pyt file)."""        self.label = "UAV Toolkit"        self.alias = "UAVToolkit"        # List of tool classes associated with this toolbox        self.tools = [SegmentAnything]    @staticmethod    def load_model(model_checkpoint_path: str, model_checkpoint_type: str, message: Any, use_gpu: bool = GPU_AVAILABLE) -> Sam:        sam = sam_model_registry[model_checkpoint_type](checkpoint=model_checkpoint_path)        if use_gpu and GPU_AVAILABLE:            sam.to("cuda")        elif not use_gpu:            sam.to("cpu")            message.addWarning("CUDA is not available. Using CPU for inference.")        return sam    @staticmethod    def raster2numpy(raster: arcpy.Raster, r_channel: str, g_channel: str, b_channel: str) -> np.ndarray:        """Convert a raster to a numpy array."""        r, g, b = raster.bandNames.index(r_channel), raster.bandNames.index(g_channel), raster.bandNames.index(b_channel)        mat = arcpy.RasterToNumPyArray(raster, arcpy.Point(raster.extent.XMin, raster.extent.YMin), nodata_to_value=0)        # get only the selected bands        return np.stack((mat[r - 1], mat[g - 1], mat[b - 1]), axis=-1)    @staticmethod    def extractingCoordinatesAndLabels(point_feature_cls: str, raster: arcpy.Raster, label_field: str = "label") -> Tuple[np.ndarray, np.ndarray]:        """Extracting the pixel coordinates and labels from a point feature class."""        pixel_coords, labels = [], []        point_sr, raster_sr = arcpy.Describe(point_feature_cls).spatialReference, raster.spatialReference        for row in arcpy.da.SearchCursor(point_feature_cls, ["SHAPE@XY", label_field]):            x, y = row[0]            if point_sr.name != raster_sr.name:                prj_pnt = arcpy.PointGeometry(arcpy.Point(x, y), point_sr).projectAs(raster_sr).firstPoint                x, y = prj_pnt.X, prj_pnt.Y            pixel_coords.append([x, y])            labels.append(row[1])        return np.array(pixel_coords), np.array(labels)    @staticmethod    def geoCood2pixelCood(leftX: float, topY: float, resolution: float, geoX: float, geoY: float) -> Tuple[float, float]:        """        Convert the geographic coordinates to the pixel coordinates.        :param leftX: the left X coordinate of the raster        :param topY: the top Y coordinate of the raster        :param resolution: the resolution of the raster        :param geoX: the geographic X coordinate        :param geoY: the geographic Y coordinate        :return: the pixel coordinates in integer        """        x = int((geoX - leftX) / resolution)        y = int((topY - geoY) / resolution)        return x, y    @staticmethod    def image_pca(image: np.ndarray) -> np.ndarray:        """        Perform PCA on the image matrix.        :param image: the image matrix with shape (H, W, C)        :return: the PCA-transformed image matrix with shape (H, W, C)        """        h, w, c = image.shape        image = image.reshape(h * w, c)        image = image - np.mean(image, axis=0)        cov = np.cov(image, rowvar=False)        eig_val, eig_vec = np.linalg.eig(cov)        idx = np.argsort(-eig_val)        eig_vec = eig_vec[:, idx]        image = np.dot(image, eig_vec)        return image.reshape(h, w, c)    @staticmethod    def recommended_pred_iou_thresh(image: np.ndarray, bin_mask: np.ndarray) -> float:        """        Recommend the predicted IoU threshold based on the first principal component of the image and the binarized mask.        :param image: the image matrix with shape (H, W, C)        :param bin_mask: the binarized mask matrix with shape (H, W)        :return:        """        pca_first = Toolbox.image_pca(image)[..., 0]    # first principal component        # calculate the correlation coefficient between the first principal component and the binarized mask        corr = np.corrcoef(pca_first.flatten(), bin_mask.flatten())[0, 1]        return min(0.4 + np.abs(corr), 0.99)class SegmentAnything(object):    def __init__(self):        """Define the tool (tool name is the name of the class)."""        self.label = "Segment Anything"        self.description = "Use a Segment Anything Model (SAM) to segment all objects in UAV images in Feature Class format."        self.canRunInBackground = True    def getParameterInfo(self) -> List[arcpy.Parameter]:        """        Define parameter definitions        """        # Model parameters        model_checkpoint_path = arcpy.Parameter(  # model checkpoint file            category="Model Checkpoint Parameters",            displayName="Model Checkpoint Path",            name="model_checkpoint_path",            datatype="DEFile",            parameterType="Required",            direction="Input",        )    # 0        # model_checkpoint_path.message = "Select a Segment Anything Model checkpoint file (e.g., sam_vit_h_4b8939.pth)"        model_checkpoint_path.filter.list = ['pth']        model_checkpoint_type = arcpy.Parameter(  # vit_h (default), vit_l, vit_b only, no other models            category="Model Checkpoint Parameters",            displayName="Model Type",            name="model_checkpoint_type",            datatype="GPString",            parameterType="Required",            direction="Input",        )    # 1        # model_checkpoint_type.message = "Select a Segment Anything Model type in {vit_h, vit_l, vit_b}"        model_checkpoint_type.filter.type = "ValueList"        model_checkpoint_type.filter.list = ["vit_h", "vit_l", "vit_b"]        model_checkpoint_type.value = "vit_h"  # default value        # Raster parameters        input_raster = arcpy.Parameter(            category="Input Raster",            displayName="Input Raster",            name="input_raster",            datatype="DERasterDataset",            parameterType="Required",            direction="Input",        )    # 2        red_channel = arcpy.Parameter(  # get the band from the input raster as the red channel            category="Input Raster",            displayName="Red Channel",            name="red_channel",            datatype="GPString",            parameterType="Required",            direction="Input",        )    # 3        red_channel.filter.type = "ValueList"        green_channel = arcpy.Parameter(  # get the band from the input raster as the green channel            category="Input Raster",            displayName="Green Channel",            name="green_channel",            datatype="GPString",            parameterType="Required",            direction="Input",        )    # 4        green_channel.filter.type = "ValueList"        blue_channel = arcpy.Parameter(  # get the band from the input raster as the blue channel            category="Input Raster",            displayName="Blue Channel",            name="blue_channel",            datatype="GPString",            parameterType="Required",            direction="Input",        )    # 5        blue_channel.filter.type = "ValueList"        # Segmentation parameters        points_per_side = arcpy.Parameter(  # must > 0            category="Segmentation Parameters",            displayName="Points per Side",            name="points_per_side",            datatype="GPLong",            parameterType="Required",            direction="Input",        )    # 6        points_per_side.filter.type = "Range"        points_per_side.filter.list = [1, math.inf]        points_per_batch = arcpy.Parameter(            # number of points per batch for the raster            category="Segmentation Parameters",            displayName="Points per Batch",            name="points_per_batch",            datatype="GPLong",            parameterType="Required",            direction="Input",        )    # 7        points_per_batch.value = int(GPU_MEMORY) if GPU_AVAILABLE else 64  # default value        points_per_batch.filter.type = "Range"        points_per_batch.filter.list = [1, math.inf]        pred_iou_thresh = arcpy.Parameter(  # must be in [0, 1]            category="Segmentation Parameters",            displayName="Predicted IoU Threshold",            name="pred_iou_thresh",            datatype="GPDouble",            parameterType="Required",            direction="Input",        )    # 8        pred_iou_thresh.filter.type = "Range"        pred_iou_thresh.filter.list = [0, 1]        stability_score_thresh = arcpy.Parameter(  # must be in [0, 1]            category="Segmentation Parameters",            displayName="Stability Score Threshold",            name="stability_score_thresh",            datatype="GPDouble",            parameterType="Required",            direction="Input",        )    # 9        stability_score_thresh.filter.type = "Range"        stability_score_thresh.filter.list = [0, 1]        stability_score_offset = arcpy.Parameter(  # no limit            category="Segmentation Parameters",            displayName="Stability Score Offset",            name="stability_score_offset",            datatype="GPDouble",            parameterType="Required",            direction="Input",        )   # 10        stability_score_offset.value = 1.0  # default value        box_nms_thresh = arcpy.Parameter(  # no limit, all real numbers            category="Segmentation Parameters",            displayName="Box NMS Threshold",            name="box_nms_thresh",            datatype="GPDouble",            parameterType="Required",            direction="Input",        )   # 11        box_nms_thresh.value = 0.7  # default value        crop_n_layers = arcpy.Parameter(  # no-negative integer            category="Segmentation Parameters",            displayName="Crop N Layers",            name="crop_n_layers",            datatype="GPLong",            parameterType="Required",            direction="Input",        )  # 12        crop_n_layers.value = 0  # default value        crop_n_layers.filter.type = "Range"        crop_n_layers.filter.list = [0, math.inf]        crop_nms_thresh = arcpy.Parameter(  # [0, 1]            category="Segmentation Parameters",            displayName="Crop NMS Threshold",            name="crop_nms_thresh",            datatype="GPDouble",            parameterType="Required",            direction="Input",        )   # 13        crop_nms_thresh.value = 0.7  # default value        crop_nms_thresh.filter.type = "Range"        crop_nms_thresh.filter.list = [0, 1]        crop_overlap_ratio = arcpy.Parameter(  # [0, 1]            category="Segmentation Parameters",            displayName="Crop Overlap Ratio",            name="crop_overlap_ratio",            datatype="GPDouble",            parameterType="Required",            direction="Input",        )   # 14        crop_overlap_ratio.value = 512 / 1500  # default value        crop_overlap_ratio.filter.type = "Range"        crop_overlap_ratio.filter.list = [0, 1]        crop_n_points_downscale_factor = arcpy.Parameter(  # [1, +inf)            category="Segmentation Parameters",            displayName="Crop N Points Downscale Factor",            name="crop_n_points_downscale_factor",            datatype="GPLong",            parameterType="Required",            direction="Input",        )   # 15        crop_n_points_downscale_factor.value = 2  # default value        crop_n_points_downscale_factor.filter.type = "Range"        crop_n_points_downscale_factor.filter.list = [1, math.inf]        min_mask_region_area = arcpy.Parameter(  # [0, +inf), if > 0, openCV is required            category="Segmentation Parameters",            displayName="Minimum Mask Region Area",            name="min_mask_region_area",            datatype="GPLong",            parameterType="Required",            direction="Input",        )    # 16        min_mask_region_area.value = 0  # default value        min_mask_region_area.filter.type = "Range"        min_mask_region_area.filter.list = [0, math.inf]        # Export parameters        output_feature_class = arcpy.Parameter(  # Output Feature Class file            category="Export Parameters",            displayName="Output Feature Class",            name="output_feature_class",            datatype="DEFeatureClass",            parameterType="Required",            direction="Output",        )    # 17        gpu_acceleration = arcpy.Parameter(  # use GPU if available            displayName="Use GPU Acceleration",            name="use_gpu",            datatype="GPBoolean",            parameterType="Required",            direction="Input",        )    # 18        gpu_acceleration.value = GPU_AVAILABLE  # default is True if GPU is available        params = [model_checkpoint_path, model_checkpoint_type,                  input_raster, red_channel, green_channel, blue_channel,                  points_per_side, points_per_batch, pred_iou_thresh, stability_score_thresh, stability_score_offset,                  box_nms_thresh, crop_n_layers, crop_nms_thresh, crop_overlap_ratio, crop_n_points_downscale_factor,                  min_mask_region_area,                  output_feature_class,                  gpu_acceleration]        return params    def isLicensed(self) -> bool:        """Set whether tool is licensed to execute."""        return True    def updateParameters(self, parameters: List[arcpy.Parameter]) -> None:        """Modify the values and properties of parameters before internal        validation is performed.  This method is called whenever a parameter        has been changed."""        if parameters[2].altered:  # if the input raster is changed            raster = arcpy.Raster(parameters[2].valueAsText)            parameters[3].filter.list = parameters[4].filter.list = parameters[5].filter.list = raster.bandNames            if parameters[3].value not in raster.bandNames:      # red channel                parameters[3].value = raster.bandNames[-1]            if parameters[4].value not in raster.bandNames:      # green channel                parameters[4].value = raster.bandNames[-2] if len(raster.bandNames) > 1 else raster.bandNames[-1]            if parameters[5].value not in raster.bandNames:      # blue channel                parameters[5].value = raster.bandNames[-3] if len(raster.bandNames) > 2 else raster.bandNames[-1]            num_obj = 0            recommended_iou_thresh = 0.88            if OPENCV_AVAILABLE:   # if openCV is available                image = Toolbox.raster2numpy(raster, parameters[3].value, parameters[4].value,                                             parameters[5].value)  # R, G, B                hists = [cv2.calcHist([image], [0, 1, 2], None, [256, 256, 256], [0, 256, 0, 256, 0, 256])]                background_ranges: List[Tuple[int, int]] = []  # store the ranges of the background                peaks = [np.argmax(hist) for hist in hists]  # get the peaks of the histograms                for peak in peaks:                    background_ranges.append((max(0, peak - 10), min(255, peak + 10)))                # binarization: bg = 0, fg = 1                bin_image = np.zeros(image.shape[:2], dtype=np.uint8)                for i, (low, high) in enumerate(background_ranges):                    bin_image[(image[:, :, i] >= low) & (image[:, :, i] <= high)] = 1                # get the contours                num_obj, _ = cv2.connectedComponents(bin_image)                recommended_iou_thresh = Toolbox.recommended_pred_iou_thresh(image, bin_image)            if not parameters[6].value:   # points_per_side                parameters[6].value = max(int(np.sqrt(num_obj) + 1), 16) if OPENCV_AVAILABLE else 32            if not parameters[8].value:   # pred_iou_thresh                parameters[8].value = recommended_iou_thresh            if not parameters[9].value:   # stability_score_thresh                parameters[9].value = min(recommended_iou_thresh + 0.05, 0.99)            if not parameters[17].value and parameters[2].value is not None:                parameters[17].value = 'seg_any_' + os.path.basename(parameters[2].valueAsText).split('.')[0] + '.shp'    def updateMessages(self, parameters: List[arcpy.Parameter]) -> None:        """Modify the messages created by internal validation for each tool        parameter.  This method is called after internal validation."""        return    def execute(self, parameters: List[arcpy.Parameter], messages) -> None:        """The source code of the tool."""        sam = Toolbox.load_model(parameters[0].valueAsText, parameters[1].valueAsText, parameters[18].value)        messages.addMessage("Model loaded: {}".format(parameters[0].valueAsText))        if parameters[16].value > 0:            if not OPENCV_AVAILABLE:                raise ImportError("Dependency import error: opencv is not available\n" +                                  "OpenCV is required for post-processing with min_mask_region_area > 0.")        mask_generater = SamAutomaticMaskGenerator(sam,                                                   points_per_side=parameters[6].value,                                                   points_per_batch=parameters[7].value,                                                   pred_iou_thresh=parameters[8].value,                                                   stability_score_thresh=parameters[9].value,                                                   stability_score_offset=parameters[10].value,                                                   box_nms_thresh=parameters[11].value,                                                   crop_n_layers=parameters[12].value,                                                   crop_nms_thresh=parameters[13].value,                                                   crop_overlap_ratio=parameters[14].value,                                                   crop_n_points_downscale_factor=parameters[15].value,                                                   min_mask_region_area=parameters[16].value,                                                   output_mode='uncompressed_rle')        messages.addMessage("Segmentation parameters set.")        # read the raster as a numpy array        ori_raster = arcpy.Raster(parameters[2].valueAsText)  # input original raster        image = Toolbox.raster2numpy(ori_raster,                                     parameters[3].value,                                     parameters[4].value,                                     parameters[5].value)        # gen masks, each mask is a 0-1 numpy array, we need to convert it to a polygon into a feature class        masks: List[Dict[str, Any]] = mask_generater.generate(image)        messages.addMessage("Masks generated.")        # cache all mask into a matrix with hte shape of the ori        all_masks_matrix = np.zeros(image.shape[:2], dtype=np.uint32)        for i, mask in enumerate(masks):            mask = amg.rle_to_mask(mask['segmentation'])            all_masks_matrix += mask.astype(np.uint32) * (i + 1)        # turn the matrix into a raster with the same spatial reference and coordinate system as the input raster        all_masks_raster: arcpy.Raster = arcpy.NumPyArrayToRaster(in_array=all_masks_matrix,                                                                  lower_left_corner=arcpy.Point(                                                                      X=ori_raster.extent.XMin,                                                                      Y=ori_raster.extent.YMin,                                                                      M=ori_raster.extent.MMin),                                                                  x_cell_size=ori_raster.meanCellWidth,                                                                  y_cell_size=ori_raster.meanCellHeight,                                                                  mdinfo=ori_raster.mdinfo)        arcpy.DefineProjection_management(in_dataset=all_masks_raster, coor_system=ori_raster.spatialReference)        messages.addMessage("Masks merged: {}".format(ori_raster.mdinfo))        # create a feature class from the raster        feature_class = arcpy.RasterToPolygon_conversion(in_raster=all_masks_raster,                                                         out_polygon_features=parameters[17].valueAsText)        # add the feature class to the current map        arcpy.SetParameterAsText(17, feature_class)        messages.addMessage("Feature class created.")        return feature_class    def postExecute(self, parameters):        """This method takes place after outputs are processed and        added to the display."""        return