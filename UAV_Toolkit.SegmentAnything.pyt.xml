<?xml version="1.0"?>
<metadata xml:lang="en"><Esri><CreaDate>20240321</CreaDate><CreaTime>11451900</CreaTime><ArcGISFormat>1.0</ArcGISFormat><SyncOnce>TRUE</SyncOnce><ModDate>20240322</ModDate><ModTime>17552000</ModTime><scaleRange><minScale>150000000</minScale><maxScale>5000</maxScale></scaleRange><ArcGISProfile>ItemDescription</ArcGISProfile></Esri><tool name="SegmentAnything" displayname="Segment Anything" toolboxalias="toolbox" xmlns=""><arcToolboxHelpPath>d:\program files\arcgis\pro\Resources\Help\gp</arcToolboxHelpPath><parameters><param name="model_checkpoint_path" displayname="Model Checkpoint Path" type="Required" direction="Input" datatype="File" expression="model_checkpoint_path"><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;str&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The path of the model checkpoint of the SAM.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;The path of the model checkpoint of the SAM.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference></param><param name="model_checkpoint_type" displayname="Model Type" type="Required" direction="Input" datatype="String" expression="vit_h | vit_l | vit_b"><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;str&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;You can choose "vit_h", "vit_l" or "vit_b", all of the model checkpoints are based on Vision Transformer, the difference is the number of layers and the number of heads in the model. &lt;/SPAN&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;P&gt;&lt;SPAN&gt;"vit_h": encoder_embed_dim=1280, encoder_depth=32, encoder_num_heads=16, encoder_global_attn_indexes=[7, 15, 23, 31];&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;SPAN&gt;"vit_l": encoder_embed_dim=1024, encoder_depth=24, encoder_num_heads=16, encoder_global_attn_indexes=[5, 11, 17, 23];&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;SPAN&gt;"vit_b": encoder_embed_dim=768, encoder_depth=12, encoder_num_heads=12, encoder_global_attn_indexes=[2, 5, 8, 11].&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;You can choose "vit_h", "vit_l" or "vit_b", all of the model checkpoints are based on Vision Transformer, the difference is the number of layers and the number of heads in the model. &lt;/SPAN&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;P&gt;&lt;SPAN&gt;"vit_h": encoder_embed_dim=1280, encoder_depth=32, encoder_num_heads=16, encoder_global_attn_indexes=[7, 15, 23, 31];&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;SPAN&gt;"vit_l": encoder_embed_dim=1024, encoder_depth=24, encoder_num_heads=16, encoder_global_attn_indexes=[5, 11, 17, 23];&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;SPAN&gt;"vit_b": encoder_embed_dim=768, encoder_depth=12, encoder_num_heads=12, encoder_global_attn_indexes=[2, 5, 8, 11].&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference></param><param name="input_raster" displayname="Input Raster" type="Required" direction="Input" datatype="Raster Dataset" expression="input_raster"><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;str&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The path to the original raster dataset.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;The path to the original raster dataset.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference></param><param name="red_channel" displayname="Red Channel" type="Required" direction="Input" datatype="String" expression="red_channel"><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;str&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The name of the band used to be the red channel.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;The name of the band used to be the red channel.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference></param><param name="green_channel" displayname="Green Channel" type="Required" direction="Input" datatype="String" expression="green_channel"><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;str&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The name of the band used to be the green channel.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;The name of the band used to be the green channel.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference></param><param name="blue_channel" displayname="Blue Channel" type="Required" direction="Input" datatype="String" expression="blue_channel"><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;str&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The name of the band used to be the blue channel.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;The name of the band used to be the blue channel.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference></param><param name="points_per_side" displayname="Points per Side" type="Required" direction="Input" datatype="Long" expression="points_per_side"><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;The number of points to be sampled along one side of the image in [1, +inf]. The total number of points is points_per_side**2.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;int&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The number of points to be sampled along one side of the image in [1, +inf]. The total number of points is points_per_side**2.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference></param><param name="points_per_batch" displayname="Points per Batch" type="Required" direction="Input" datatype="Long" expression="points_per_batch"><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;Sets the number of points run simultaneously by the model in [1, +inf]. Higher numbers may be faster but use more GPU memory.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;int&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Sets the number of points run simultaneously by the model in [1, +inf]. Higher numbers may be faster but use more GPU memory.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference></param><param name="pred_iou_thresh" displayname="Predicted IoU Threshold" type="Required" direction="Input" datatype="Double" expression="pred_iou_thresh"><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;A filtering threshold in [0,1], using the stability of the mask under changes to the cutoff used to binarize the model's mask predictions.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;float&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A filtering threshold in [0,1], using the stability of the mask under changes to the cutoff used to binarize the model's mask predictions.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference></param><param name="stability_score_thresh" displayname="Stability Score Threshold" type="Required" direction="Input" datatype="Double" expression="stability_score_thresh"><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;A filtering threshold in [0,1], using the stability of the mask under changes to the cutoff used to binarize the model's mask predictions.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;float&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A filtering threshold in [0,1], using the stability of the mask under changes to the cutoff used to binarize the model's mask predictions.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference></param><param name="stability_score_offset" displayname="Stability Score Offset" type="Required" direction="Input" datatype="Double" expression="stability_score_offset"><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;The amount to shift the cutoff when calculated the stability score.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;float&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The amount to shift the cutoff when calculated the stability score.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference></param><param name="box_nms_thresh" displayname="Box NMS Threshold" type="Required" direction="Input" datatype="Double" expression="box_nms_thresh"><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;The box IoU cutoff used by non-maximal suppression to filter duplicate masks, [0, 1].&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;float&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The box IoU cutoff used by non-maximal suppression to filter duplicate masks, [0, 1].&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference></param><param name="crop_n_layers" displayname="Crop N Layers" type="Required" direction="Input" datatype="Long" expression="crop_n_layers"><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;If &amp;gt;0, mask prediction will be run again on crops of the image. Sets the number of layers to run, where each layer has 2**i_layer number of image crops.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;int&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;If &amp;gt;0, mask prediction will be run again on crops of the image. Sets the number of layers to run, where each layer has 2**i_layer number of image crops.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference></param><param name="crop_nms_thresh" displayname="Crop NMS Threshold" type="Required" direction="Input" datatype="Double" expression="crop_nms_thresh"><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;The box IoU cutoff used by non-maximal suppression to filter duplicate masks between different crops, [0, 1].&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;float&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The box IoU cutoff used by non-maximal suppression to filter duplicate masks between different crops, [0, 1].&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference></param><param name="crop_overlap_ratio" displayname="Crop Overlap Ratio" type="Required" direction="Input" datatype="Double" expression="crop_overlap_ratio"><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;Sets the degree to which crops overlap. In the first crop layer, crops will overlap by this fraction of the image length. Later layers with more crops scale down this overlap. The value can be set in [0, 1].&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;float&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Sets the degree to which crops overlap. In the first crop layer, crops will overlap by this fraction of the image length. Later layers with more crops scale down this overlap. The value can be set in [0, 1].&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference></param><param name="crop_n_points_downscale_factor" displayname="Crop N Points Downscale Factor" type="Required" direction="Input" datatype="Long" expression="crop_n_points_downscale_factor"><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;The number of points-per-side sampled in layer n is scaled down by crop_n_points_downscale_factor**n.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;int&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The number of points-per-side sampled in layer n is scaled down by crop_n_points_downscale_factor**n.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference></param><param name="min_mask_region_area" displayname="Minimum Mask Region Area" type="Required" direction="Input" datatype="Long" expression="min_mask_region_area"><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;int&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;If &amp;gt;0, postprocessing will be applied to remove disconnected regions and holes in masks with area smaller than min_mask_region_area. Requires opencv, [0, +inf].&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;If &amp;gt;0, postprocessing will be applied to remove disconnected regions and holes in masks with area smaller than min_mask_region_area. Requires opencv, [0, +inf].&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference></param><param name="output_feature_class" displayname="Output Vector" type="Required" direction="Output" datatype="Feature Class" expression="output_feature_class"><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;str&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Config the path and the name of the Feature Class to export.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;Config the path and the name of the Feature Class to export.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference></param><param name="use_gpu" displayname="Use GPU Acceleration" type="Required" direction="Input" datatype="Boolean" expression="use_gpu"><pythonReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN STYLE="font-weight:bold;"&gt;bool&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;This parameter determines whether the computer will use the GPU to accelerate the computation. Note: If the GPU is not available, even if this parameter is checked.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</pythonReference><dialogReference>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;This parameter determines whether the computer will use the GPU to accelerate the computation. Note: If the GPU is not available, even if this parameter is checked.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</dialogReference></param></parameters><summary>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;Use Segment Anything Model (SAM) to generate masks of objects in Feature Class format.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</summary><usage>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;This tool, named "Segment Anything", is part of the UAV Toolkit. It uses a Segment Anything Model (SAM) to generate masks of objects in Feature Class format from UAV images. The tool requires several parameters, including the model checkpoint path and type, input raster, red/green/blue channels, and various segmentation parameters. The tool also supports GPU acceleration if available. The output is a Feature Class containing the segmented objects. The tool is designed to be used within the ArcGIS environment.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</usage><scriptExamples><scriptExample><title>Simple Examples</title><code>import arcpy

uav_toolkit = arcpy.ImportToolbox('path/to/UAV_Toolkit.pyt')   # load toolbox

uav_toolkit.SegmentAnything("path/to/sam_vit_h_4b8939.pth", "vit_h", "path/to/original/raster.tif", "Band_3", "Band_2", "Band_1", 64, 6, 0.88, 0.95, 1, 0.7, 0, 0.7, 512/1500, 2, 10, "path/to/the/result_vit_h.shp", True)

uav_toolkit.SegmentAnything("path/to/sam_vit_l_0b3195.pth", "vit_l", "path/to/original/raster.tif", "Band_3", "Band_2", "Band_1", 64, 6, 0.88, 0.95, 1, 0.7, 0, 0.7, 512/1500, 2, 10, "path/to/the/result_vit_l.shp", True)

uav_toolkit.SegmentAnything("path/to/sam_vit_b_01ec64.pth", "vit_b", "path/to/original/raster.tif", "Band_3", "Band_2", "Band_1", 64, 6, 0.88, 0.95, 1, 0.7, 0, 0.7, 512/1500, 2, 10, "path/to/the/result_vit_b.shp", True)</code><para>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;To call the &amp;lt;code&amp;gt;SegmentAnything&amp;lt;/code&amp;gt; function, you need to import the toolbox using arcpy.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</para></scriptExample></scriptExamples></tool><dataIdInfo><idCitation><resTitle>Segment Anything</resTitle></idCitation><searchKeys><keyword>seg_any</keyword></searchKeys><idCredit>Author: &lt;a href="https://github.com/Jaffe2718"&gt;李昌哲&lt;/a&gt;</idCredit><resConst><Consts><useLimit>&lt;DIV STYLE="text-align:Left;"&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;P&gt;&lt;SPAN&gt;This tool is open source and licensed under the Apache License, Version 2.0 (the "License"). You may not use this tool except in compliance with the License. You may obtain a copy of the License at &amp;lt;a href="https://github.com/Jaffe2718/uav_toolkit/blob/master/LICENSE"&amp;gt;https://github.com/Jaffe2718/uav_toolkit/blob/master/LICENSE&amp;lt;/a&amp;gt;. Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/SPAN&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</useLimit></Consts></resConst></dataIdInfo><distInfo><distributor><distorFormat><formatName>ArcToolbox Tool</formatName></distorFormat></distributor></distInfo><mdHrLv><ScopeCd value="005"/></mdHrLv><mdDateSt Sync="TRUE">20240322</mdDateSt><Binary><Thumbnail><Data EsriPropertyType="PictureX">/9j/4AAQSkZJRgABAQEAkACQAAD/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsK
CwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQU
FBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAAgACADASIA
AhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQA
AAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3
ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWm
p6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEA
AwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSEx
BhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElK
U1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3
uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD9BPjh
+0N4V+Auk29xrsk11qF1n7JplmA002OrHJAVAf4ifoCeK8m+F/8AwUC8H+OPEUWka7pVx4S+0SCO
3vZ7hZ7cknAErBVMeTjnBUdyBzXC/DHw3B+0l+1x4v8AFHiCJdQ0Dw25jtLSdd0bbHMdupU8bflk
kI7t65Ndb+314X8IXvg/SZpLFR46nuFh0t7NAJpowQHSQAZeMAgL3DFccFgf03D5TldLEUcpxNOU
q9SKcpJ/A2rpcuzSWsm/X0+CrZnjqlCrmVGpGNGDaUWviSdm77q70SR6L8Sv2qtF8F+Jp/DeiaLq
HjLXbXP2u30sZS3x95WYBiWHcAEDoSDxXVfBz47eG/jVp1xLpDS2moWv/H1pt2AJogeA3BIZSe4/
HFeBf8E8vFWjSaD4j8OSWkVp4rt5/tM8z5866g4UZzz+7bII6DeD1JrR+OdknwZ/aS8C+O9LAtLX
X5jZ6rHHwr/MiSMw7lkkVv8Aejz15rKvk+A+s1Mnp05RrRi3GbfxtLms47JNX5bO663FTzPHQoQz
SpUUqMpJSgl8Cb5bqW7adr3Vn0scB8BviZpP7MvxD+JGieMIbuGS4uEEclvDvLGF5SuBkcOsoZT0
xj1ruvgfoeq/tDfGC5+LHiS2eHQdMfytEs5fu71PybfUJksT3kbjoQPpPxN8NfCnjO6judd8OaZq
9zGNqTXlqkjhfTcRnHtW7ZWVvptpDa2lvFa2sKhIoYUCIijoFUcAewrmxvElCvGpXw9FxxFWKjOT
d0kkk+VdOZJX7LY2wfD9ejOnRr1VLD0pOUYpatttrmfXlb07nxj+094B1j4GfFjTfjR4NgxaS3AO
rW6ZCCVuGLgf8s5gcE9n5zlhWZ8ZvjXpH7TGtfDfw74StL1r574TXK3EWDAzbRt4PzBQHZmHAAHP
XH3FeWdvqFrNa3UEdzbTIY5IZkDo6kYKsp4IPoa57wz8MPCHgu8kvNB8M6VpF3Iu1p7O0SN9p6ru
AyB7dKnBcR0KVOlVxNFyr0U1CSdk000lLvy30NcZkNatKpSoVVGjVac421umm+Xte2p//9k=</Data></Thumbnail></Binary></metadata>
